{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-10T02:28:59.209555Z",
     "start_time": "2024-09-10T02:28:59.205199Z"
    }
   },
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T02:29:19.251351Z",
     "start_time": "2024-09-10T02:29:18.333682Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_json('resources/embold_train.json')\n",
    "df['combined'] = df['title']+'. '+df['body']\n",
    "df.head()"
   ],
   "id": "9fedda6172ea583e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                               title  \\\n",
       "0                                  y-zoom piano roll   \n",
       "1                        buggy behavior in selection   \n",
       "2                                auto update feature   \n",
       "3                 filter out noisy endpoints in logs   \n",
       "4  enable pid on / pid off alarm actions for ardu...   \n",
       "\n",
       "                                                body  label  \\\n",
       "0        a y-zoom on the piano roll would be useful.      1   \n",
       "1  ! screenshot from 2016-02-23 21 27 40  https:/...      0   \n",
       "2  hi,\\r \\r great job so far, @saenzramiro ! : \\r...      1   \n",
       "3  i think we should stop logging requests to:\\r ...      1   \n",
       "4  expected behavior\\r alarm actions pid on and p...      0   \n",
       "\n",
       "                                            combined  \n",
       "0  y-zoom piano roll. a y-zoom on the piano roll ...  \n",
       "1  buggy behavior in selection. ! screenshot from...  \n",
       "2  auto update feature. hi,\\r \\r great job so far...  \n",
       "3  filter out noisy endpoints in logs. i think we...  \n",
       "4  enable pid on / pid off alarm actions for ardu...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>label</th>\n",
       "      <th>combined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>y-zoom piano roll</td>\n",
       "      <td>a y-zoom on the piano roll would be useful.</td>\n",
       "      <td>1</td>\n",
       "      <td>y-zoom piano roll. a y-zoom on the piano roll ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>buggy behavior in selection</td>\n",
       "      <td>! screenshot from 2016-02-23 21 27 40  https:/...</td>\n",
       "      <td>0</td>\n",
       "      <td>buggy behavior in selection. ! screenshot from...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>auto update feature</td>\n",
       "      <td>hi,\\r \\r great job so far, @saenzramiro ! : \\r...</td>\n",
       "      <td>1</td>\n",
       "      <td>auto update feature. hi,\\r \\r great job so far...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>filter out noisy endpoints in logs</td>\n",
       "      <td>i think we should stop logging requests to:\\r ...</td>\n",
       "      <td>1</td>\n",
       "      <td>filter out noisy endpoints in logs. i think we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>enable pid on / pid off alarm actions for ardu...</td>\n",
       "      <td>expected behavior\\r alarm actions pid on and p...</td>\n",
       "      <td>0</td>\n",
       "      <td>enable pid on / pid off alarm actions for ardu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T02:29:37.865419Z",
     "start_time": "2024-09-10T02:29:37.827922Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_bug = df[df['label']==0]\n",
    "df_feature = df[df['label']==1]\n",
    "df_question = df[df['label']==2]"
   ],
   "id": "8781f3cc7be3a305",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T02:38:20.879966Z",
     "start_time": "2024-09-10T02:38:20.864Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print('Number of datapoints with label as Bug :',df_bug)\n",
    "print('Number of datapoints with label as Feature :',df_feature)\n",
    "print('Number of datapoints with label as Question :',df_question)"
   ],
   "id": "b7f56c88dfac9c0d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of datapoints with label as Bug :                                                     title  \\\n",
      "1                             buggy behavior in selection   \n",
      "4       enable pid on / pid off alarm actions for ardu...   \n",
      "5                           script stopped adding video's   \n",
      "9       en la org ull-esit-pl-1617 people info /nico/ ...   \n",
      "15                                 filter floating points   \n",
      "...                                                   ...   \n",
      "149994         copy module fails with json and with_items   \n",
      "149996  decoder displays some neurovault images incorr...   \n",
      "149997    parser should return an error, not an exception   \n",
      "149998  errorexception  array to string conversion on ...   \n",
      "149999                   ignore headings in code sections   \n",
      "\n",
      "                                                     body  label  \\\n",
      "1       ! screenshot from 2016-02-23 21 27 40  https:/...      0   \n",
      "4       expected behavior\\r alarm actions pid on and p...      0   \n",
      "5       a recent change in the youtube layout broke th...      0   \n",
      "9       \\r crguezl>ull-esit-pl-1617> people info /nico...      0   \n",
      "15      background\\r \\r we have identified a small num...      0   \n",
      "...                                                   ...    ...   \n",
      "149994  issue type:  bug report       ansible version:...      0   \n",
      "149996  as noted by @nicholst, some neurovault images ...      0   \n",
      "149997  for this raml:\\r \\r    yaml\\r  %raml 1.0\\r tit...      0   \n",
      "149998       see above.\\r \\r occurs in branch   routes  .      0   \n",
      "149999  do not process headings inside quotes and code...      0   \n",
      "\n",
      "                                                 combined  \n",
      "1       buggy behavior in selection. ! screenshot from...  \n",
      "4       enable pid on / pid off alarm actions for ardu...  \n",
      "5       script stopped adding video's. a recent change...  \n",
      "9       en la org ull-esit-pl-1617 people info /nico/ ...  \n",
      "15      filter floating points. background\\r \\r we hav...  \n",
      "...                                                   ...  \n",
      "149994  copy module fails with json and with_items. is...  \n",
      "149996  decoder displays some neurovault images incorr...  \n",
      "149997  parser should return an error, not an exceptio...  \n",
      "149998  errorexception  array to string conversion on ...  \n",
      "149999  ignore headings in code sections. do not proce...  \n",
      "\n",
      "[66827 rows x 4 columns]\n",
      "Number of datapoints with label as Feature :                                                     title  \\\n",
      "0                                       y-zoom piano roll   \n",
      "2                                     auto update feature   \n",
      "3                      filter out noisy endpoints in logs   \n",
      "6                   add the translations of v3.1.0-beta.4   \n",
      "8       bot should post to listings periodically inste...   \n",
      "...                                                   ...   \n",
      "149983  rbac: application owners should be allowed to ...   \n",
      "149986  please make clicking on the filters labels not...   \n",
      "149990         improve and clean users 'configs' rest api   \n",
      "149991           applications: approve applicant directly   \n",
      "149995  suggestion   getinventorylist should return ra...   \n",
      "\n",
      "                                                     body  label  \\\n",
      "0             a y-zoom on the piano roll would be useful.      1   \n",
      "2       hi,\\r \\r great job so far, @saenzramiro ! : \\r...      1   \n",
      "3       i think we should stop logging requests to:\\r ...      1   \n",
      "6       release electron v3.1.0-beta.4 - electron/elec...      1   \n",
      "8       postbotstats  ; is only called when the bot co...      1   \n",
      "...                                                   ...    ...   \n",
      "149983  is this a bug report or feature request?  :\\r ...      1   \n",
      "149986  50% of the time i click accidentally just to o...      1   \n",
      "149990  currently there are 8 web services for configs...      1   \n",
      "149991  for internetix students, application managemen...      1   \n",
      "149995  <!-- note: anything within these brackets will...      1   \n",
      "\n",
      "                                                 combined  \n",
      "0       y-zoom piano roll. a y-zoom on the piano roll ...  \n",
      "2       auto update feature. hi,\\r \\r great job so far...  \n",
      "3       filter out noisy endpoints in logs. i think we...  \n",
      "6       add the translations of v3.1.0-beta.4. release...  \n",
      "8       bot should post to listings periodically inste...  \n",
      "...                                                   ...  \n",
      "149983  rbac: application owners should be allowed to ...  \n",
      "149986  please make clicking on the filters labels not...  \n",
      "149990  improve and clean users 'configs' rest api. cu...  \n",
      "149991  applications: approve applicant directly. for ...  \n",
      "149995  suggestion   getinventorylist should return ra...  \n",
      "\n",
      "[69106 rows x 4 columns]\n",
      "Number of datapoints with label as Question :                                                     title  \\\n",
      "7       proposal  loadtranslation   to lazy load scope...   \n",
      "11                             null or    in jsonexporter   \n",
      "14                 collectionprovider  support pagination   \n",
      "16      i2cwrite error on debian 9.2:  cannot read pro...   \n",
      "50      is performupdatesanimated always necessary whe...   \n",
      "...                                                   ...   \n",
      "149929       customprimarydraweritem no where to be found   \n",
      "149934  php strings translations are not propagated to...   \n",
      "149966  fatal error: double value cannot be converted ...   \n",
      "149992                   figure out what to do with ghost   \n",
      "149993   specflow afterscenario runs after nunit teardown   \n",
      "\n",
      "                                                     body  label  \\\n",
      "7       php\\r public function loadtranslation  \\r {\\r ...      2   \n",
      "11      \\r  \\ rows\\ : {\\r     \\ left\\ :  \\r       {\\r ...      2   \n",
      "14      it would be very helpful if support for pagina...      2   \n",
      "16      would love for this to be working, but sadly, ...      2   \n",
      "50      i've been implementing iglistkit on my current...      2   \n",
      "...                                                   ...    ...   \n",
      "149929  android studio can't resolve  customprimarydra...      2   \n",
      "149934  steps to reproduce\\r 1. setup a project using ...      2   \n",
      "149966  what did you do?\\r \\r rare dataset inputs pass...      2   \n",
      "149992  currently the articles module is disabled and ...      2   \n",
      "149993  hi @unickq,\\r \\r thanks again for your help be...      2   \n",
      "\n",
      "                                                 combined  \n",
      "7       proposal  loadtranslation   to lazy load scope...  \n",
      "11      null or    in jsonexporter. \\r  \\ rows\\ : {\\r ...  \n",
      "14      collectionprovider  support pagination. it wou...  \n",
      "16      i2cwrite error on debian 9.2:  cannot read pro...  \n",
      "50      is performupdatesanimated always necessary whe...  \n",
      "...                                                   ...  \n",
      "149929  customprimarydraweritem no where to be found. ...  \n",
      "149934  php strings translations are not propagated to...  \n",
      "149966  fatal error: double value cannot be converted ...  \n",
      "149992  figure out what to do with ghost. currently th...  \n",
      "149993  specflow afterscenario runs after nunit teardo...  \n",
      "\n",
      "[14067 rows x 4 columns]\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T02:40:10.030328Z",
     "start_time": "2024-09-10T02:40:10.018418Z"
    }
   },
   "cell_type": "code",
   "source": [
    "label_counts = df.label.value_counts().sort_index()\n",
    "label_counts"
   ],
   "id": "9dcff5c4041b4be3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    66827\n",
       "1    69106\n",
       "2    14067\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T02:29:50.121730Z",
     "start_time": "2024-09-10T02:29:49.338130Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import nltk\n",
    "import re\n",
    "import string"
   ],
   "id": "eea6844591dac046",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### clean data",
   "id": "ad5a5585e5c1df20"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T02:29:57.848283Z",
     "start_time": "2024-09-10T02:29:57.842773Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def clean_text(text):\n",
    "    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n",
    "    and remove words containing numbers'''\n",
    "    text = text.lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "\n",
    "    return text"
   ],
   "id": "fc650d693d3b1d58",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T02:31:00.216282Z",
     "start_time": "2024-09-10T02:31:00.211244Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from string import punctuation\n",
    "from nltk.corpus import stopwords"
   ],
   "id": "2b53f49836b6e6e0",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### remove stop word\n",
   "id": "eae6b8faa78d958f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T02:32:19.235533Z",
     "start_time": "2024-09-10T02:32:19.229221Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def punctuation_stopwords_removal(git_text):\n",
    "    # filters charecter-by-charecter : ['h', 'e', 'e', 'l', 'o', 'o', ' ', 'm', 'y', ' ', 'n', 'a', 'm', 'e', ' ', 'i', 's', ' ', 'p', 'u', 'r', 'v', 'a']\n",
    "    remove_punctuation = [ch for ch in git_text if ch not in punctuation]\n",
    "    # convert them back to sentences and split into words\n",
    "    remove_punctuation = \"\".join(remove_punctuation).split()\n",
    "    filtered_git_text = [word.lower() for word in remove_punctuation if word.lower() not in stopwords.words('english')]\n",
    "    return filtered_git_text"
   ],
   "id": "82544db236b81845",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T02:32:48.050304Z",
     "start_time": "2024-09-10T02:32:47.832444Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from collections import Counter\n",
    "import plotly.express as px"
   ],
   "id": "9be1a07b2d2469d4",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T02:32:49.341841Z",
     "start_time": "2024-09-10T02:32:49.330957Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def plot_most_common_words(df_category, category):\n",
    "    df_category['combined'] = df_category['combined'].apply(lambda x: x.replace(\"\\\\r\", \"\"))\n",
    "    df_category['combined'] = df_category['combined'].apply(lambda x: clean_text(x))\n",
    "    \n",
    "    df_category[\"combined\"] = df_category[\"combined\"].apply(punctuation_stopwords_removal)\n",
    "    \n",
    "    word_list = []\n",
    "    \n",
    "    for i, j in df_category.iterrows():\n",
    "        for word in j['combined']:\n",
    "            word_list.append(word)\n",
    "        \n",
    "    count_dict = Counter(word_list)\n",
    "    most_common_words_df = pd.DataFrame(count_dict.most_common(20), columns=['word', 'count'])\n",
    "    fig = px.histogram(most_common_words_df,\n",
    "                       x='word', \n",
    "                       y='count',\n",
    "                       title='Most common terms used while refering to a GitHub {}'.format(category),\n",
    "                       color_discrete_sequence=['#843B62'] )\n",
    "    fig.show()"
   ],
   "id": "e5a20961ef717773",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "####\n",
    "label 0: Bug\n",
    "label 1: Feature\n",
    "label 2: Question"
   ],
   "id": "9c8f991d39a4ae29"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T02:34:51.040532Z",
     "start_time": "2024-09-10T02:34:38.234073Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df['combined'] = df['combined'].apply(lambda x: x.replace(\"\\\\r\", \"\"))\n",
    "df['combined'] = df['combined'].apply(lambda x: clean_text(x))\n",
    "df.head()"
   ],
   "id": "30701f0bf4121b6c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                               title  \\\n",
       "0                                  y-zoom piano roll   \n",
       "1                        buggy behavior in selection   \n",
       "2                                auto update feature   \n",
       "3                 filter out noisy endpoints in logs   \n",
       "4  enable pid on / pid off alarm actions for ardu...   \n",
       "\n",
       "                                                body  label  \\\n",
       "0        a y-zoom on the piano roll would be useful.      1   \n",
       "1  ! screenshot from 2016-02-23 21 27 40  https:/...      0   \n",
       "2  hi,\\r \\r great job so far, @saenzramiro ! : \\r...      1   \n",
       "3  i think we should stop logging requests to:\\r ...      1   \n",
       "4  expected behavior\\r alarm actions pid on and p...      0   \n",
       "\n",
       "                                            combined  \n",
       "0  yzoom piano roll a yzoom on the piano roll wou...  \n",
       "1  buggy behavior in selection  screenshot from  ...  \n",
       "2  auto update feature hi  great job so far saenz...  \n",
       "3  filter out noisy endpoints in logs i think we ...  \n",
       "4  enable pid on  pid off alarm actions for  expe...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>label</th>\n",
       "      <th>combined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>y-zoom piano roll</td>\n",
       "      <td>a y-zoom on the piano roll would be useful.</td>\n",
       "      <td>1</td>\n",
       "      <td>yzoom piano roll a yzoom on the piano roll wou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>buggy behavior in selection</td>\n",
       "      <td>! screenshot from 2016-02-23 21 27 40  https:/...</td>\n",
       "      <td>0</td>\n",
       "      <td>buggy behavior in selection  screenshot from  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>auto update feature</td>\n",
       "      <td>hi,\\r \\r great job so far, @saenzramiro ! : \\r...</td>\n",
       "      <td>1</td>\n",
       "      <td>auto update feature hi  great job so far saenz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>filter out noisy endpoints in logs</td>\n",
       "      <td>i think we should stop logging requests to:\\r ...</td>\n",
       "      <td>1</td>\n",
       "      <td>filter out noisy endpoints in logs i think we ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>enable pid on / pid off alarm actions for ardu...</td>\n",
       "      <td>expected behavior\\r alarm actions pid on and p...</td>\n",
       "      <td>0</td>\n",
       "      <td>enable pid on  pid off alarm actions for  expe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T02:34:58.585782Z",
     "start_time": "2024-09-10T02:34:58.565120Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df.drop(['title', 'body'], axis=1, inplace=True)\n",
    "df.head()\n",
    "df_test_for_example = df.copy()"
   ],
   "id": "da84e3de7c727a21",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T02:35:08.675942Z",
     "start_time": "2024-09-10T02:35:04.402317Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import transformers\n",
    "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "from torch.utils.data import Dataset, DataLoader"
   ],
   "id": "6096438d587fef4d",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T02:35:35.259687Z",
     "start_time": "2024-09-10T02:35:35.244764Z"
    }
   },
   "cell_type": "code",
   "source": [
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)"
   ],
   "id": "1faf0ee1a62c2628",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1cedb0612d0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T02:35:46.054780Z",
     "start_time": "2024-09-10T02:35:46.049615Z"
    }
   },
   "cell_type": "code",
   "source": "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")",
   "id": "9e8390c75835e286",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### loading our BERT model ",
   "id": "1060063234889b91"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T02:46:15.390088Z",
     "start_time": "2024-09-10T02:46:15.384055Z"
    }
   },
   "cell_type": "code",
   "source": "BERT_PATH = \"bert-base-uncased\"",
   "id": "a4476a8912250fa3",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T02:46:53.225352Z",
     "start_time": "2024-09-10T02:46:53.221070Z"
    }
   },
   "cell_type": "code",
   "source": "BERT_UNCASED = 'bert-base-uncased/bert-base-uncased'",
   "id": "f03afca6f4839987",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### loading the pre-trained BertTokenizer",
   "id": "88c5ff9cd8ace08d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T02:48:28.408625Z",
     "start_time": "2024-09-10T02:48:28.345644Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# tokenizer = BertTokenizer.from_pretrained(BERT_UNCASED)\n",
    "tokenizer = BertTokenizer.from_pretrained(BERT_PATH)"
   ],
   "id": "6876ef63ad6c8f70",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T02:48:49.159473Z",
     "start_time": "2024-09-10T02:48:49.154006Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# some basic operations to understand how BERT converts a sentence into tokens and then into IDs\n",
    "sample_body = 'script stopped adding videos saenzramiro abc xyz'\n",
    "tokens = tokenizer.tokenize(sample_body)\n",
    "token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "print(f' Sentence: {sample_body}')\n",
    "print(f'   Tokens: {tokens}')\n",
    "print(f'Token IDs: {token_ids}')"
   ],
   "id": "66f493f7ab8deb57",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Sentence: script stopped adding videos saenzramiro abc xyz\n",
      "   Tokens: ['script', 'stopped', 'adding', 'videos', 'sa', '##en', '##z', '##ram', '##iro', 'abc', 'x', '##y', '##z']\n",
      "Token IDs: [5896, 3030, 5815, 6876, 7842, 2368, 2480, 6444, 9711, 5925, 1060, 2100, 2480]\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T02:50:12.960262Z",
     "start_time": "2024-09-10T02:50:12.946656Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# using encode_plus to add special tokens : [CLS]:101, [SEP]:102, [PAD]:0\n",
    "encodings = tokenizer.encode_plus(\n",
    "            sample_body,\n",
    "            max_length=32,\n",
    "            add_special_tokens=True,\n",
    "            return_token_type_ids=False,\n",
    "            pad_to_max_length=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    ")\n",
    "\n",
    "encodings.keys()"
   ],
   "id": "142739f2607f7ffb",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T02:50:38.644476Z",
     "start_time": "2024-09-10T02:50:38.635780Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print('Input IDs : {}'.format(encodings['input_ids'][0]))\n",
    "print('\\nAttention Mask : {}'.format(encodings['attention_mask'][0]))"
   ],
   "id": "254833b656cd29ce",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs : tensor([ 101, 5896, 3030, 5815, 6876, 7842, 2368, 2480, 6444, 9711, 5925, 1060,\n",
      "        2100, 2480,  102,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0])\n",
      "\n",
      "Attention Mask : tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T02:51:32.314443Z",
     "start_time": "2024-09-10T02:51:32.308914Z"
    }
   },
   "cell_type": "code",
   "source": "MAX_LENGTH = 512",
   "id": "4e4c4df002eec2b7",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T02:51:44.964598Z",
     "start_time": "2024-09-10T02:51:44.957183Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class GitHubCommitMessages(Dataset):\n",
    "    \n",
    "    def __init__(self, commit_message, label, tokenizer, max_len):\n",
    "        self.commit_message = commit_message\n",
    "        self.label = label\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.commit_message)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        commit_message = str(self.commit_message[item])\n",
    "        label = self.label[item]\n",
    "        \n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "        commit_message,\n",
    "        add_special_tokens=True,\n",
    "        max_length=self.max_len,\n",
    "        return_token_type_ids=False,\n",
    "        pad_to_max_length=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt')\n",
    "        return {\n",
    "        'commit_message': commit_message,\n",
    "         'input_ids': encoding['input_ids'],\n",
    "         'attention_mask': encoding['attention_mask'],\n",
    "         'label': torch.tensor(label, dtype=torch.long)\n",
    "          }"
   ],
   "id": "149fa10cb3323131",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T02:51:55.673713Z",
     "start_time": "2024-09-10T02:51:55.669158Z"
    }
   },
   "cell_type": "code",
   "source": "from sklearn.model_selection import train_test_split",
   "id": "503307b10f5135ba",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T02:52:05.534050Z",
     "start_time": "2024-09-10T02:52:05.524419Z"
    }
   },
   "cell_type": "code",
   "source": "df.head()",
   "id": "9a217896d973ef87",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   label                                           combined\n",
       "0      1  yzoom piano roll a yzoom on the piano roll wou...\n",
       "1      0  buggy behavior in selection  screenshot from  ...\n",
       "2      1  auto update feature hi  great job so far saenz...\n",
       "3      1  filter out noisy endpoints in logs i think we ...\n",
       "4      0  enable pid on  pid off alarm actions for  expe..."
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>combined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>yzoom piano roll a yzoom on the piano roll wou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>buggy behavior in selection  screenshot from  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>auto update feature hi  great job so far saenz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>filter out noisy endpoints in logs i think we ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>enable pid on  pid off alarm actions for  expe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T02:52:14.489428Z",
     "start_time": "2024-09-10T02:52:14.484968Z"
    }
   },
   "cell_type": "code",
   "source": "df = df[:2000]",
   "id": "51b4e22a3252b559",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T02:52:20.881928Z",
     "start_time": "2024-09-10T02:52:20.876023Z"
    }
   },
   "cell_type": "code",
   "source": "df.shape",
   "id": "f0e2eaa45176d548",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T14:48:42.070870Z",
     "start_time": "2024-09-23T14:48:42.048760Z"
    }
   },
   "cell_type": "code",
   "source": [
    "training_data, testing_data = train_test_split(\n",
    "    df,\n",
    "    test_size=0.1,\n",
    "    random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "testing_data, validation_data = train_test_split(\n",
    "    testing_data,\n",
    "    test_size=0.5,\n",
    "    random_state=RANDOM_SEED\n",
    ")"
   ],
   "id": "9b09eec701465203",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m training_data, testing_data \u001B[38;5;241m=\u001B[39m train_test_split(\n\u001B[0;32m      2\u001B[0m     df,\n\u001B[0;32m      3\u001B[0m     test_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.1\u001B[39m,\n\u001B[0;32m      4\u001B[0m     random_state\u001B[38;5;241m=\u001B[39mRANDOM_SEED\n\u001B[0;32m      5\u001B[0m )\n\u001B[0;32m      7\u001B[0m testing_data, validation_data \u001B[38;5;241m=\u001B[39m train_test_split(\n\u001B[0;32m      8\u001B[0m     testing_data,\n\u001B[0;32m      9\u001B[0m     test_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.5\u001B[39m,\n\u001B[0;32m     10\u001B[0m     random_state\u001B[38;5;241m=\u001B[39mRANDOM_SEED\n\u001B[0;32m     11\u001B[0m )\n",
      "\u001B[1;31mNameError\u001B[0m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T14:49:19.343942Z",
     "start_time": "2024-09-23T14:49:19.324478Z"
    }
   },
   "cell_type": "code",
   "source": "training_data.shape, testing_data.shape, validation_data.shape",
   "id": "498f99ba32f26df0",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m training_data\u001B[38;5;241m.\u001B[39mshape, testing_data\u001B[38;5;241m.\u001B[39mshape, validation_data\u001B[38;5;241m.\u001B[39mshape\n",
      "\u001B[1;31mNameError\u001B[0m: name 'training_data' is not defined"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T14:47:13.511031Z",
     "start_time": "2024-09-23T14:47:13.482291Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_data_loader(data, tokenizer, max_len, batch_size):\n",
    "    \n",
    "    ds = GitHubCommitMessages(commit_message=data.combined.to_numpy(),\n",
    "    label=data.label.to_numpy(),\n",
    "    tokenizer=tokenizer,\n",
    "    max_len=max_len)\n",
    "    \n",
    "    return DataLoader(\n",
    "    ds,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=4)\n",
    "\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "train_data_loader = create_data_loader(training_data, tokenizer, MAX_LENGTH, BATCH_SIZE)\n",
    "testing_data_loader = create_data_loader(testing_data, tokenizer, MAX_LENGTH, BATCH_SIZE)\n",
    "val_data_loader = create_data_loader(validation_data, tokenizer, MAX_LENGTH, BATCH_SIZE)"
   ],
   "id": "17cc28ce673c413a",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 15\u001B[0m\n\u001B[0;32m      8\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m DataLoader(\n\u001B[0;32m      9\u001B[0m     ds,\n\u001B[0;32m     10\u001B[0m     batch_size\u001B[38;5;241m=\u001B[39mbatch_size,\n\u001B[0;32m     11\u001B[0m     num_workers\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m4\u001B[39m)\n\u001B[0;32m     14\u001B[0m BATCH_SIZE \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m16\u001B[39m\n\u001B[1;32m---> 15\u001B[0m train_data_loader \u001B[38;5;241m=\u001B[39m create_data_loader(training_data, tokenizer, MAX_LENGTH, BATCH_SIZE)\n\u001B[0;32m     16\u001B[0m testing_data_loader \u001B[38;5;241m=\u001B[39m create_data_loader(testing_data, tokenizer, MAX_LENGTH, BATCH_SIZE)\n\u001B[0;32m     17\u001B[0m val_data_loader \u001B[38;5;241m=\u001B[39m create_data_loader(validation_data, tokenizer, MAX_LENGTH, BATCH_SIZE)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'training_data' is not defined"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T12:43:40.494994Z",
     "start_time": "2024-09-23T12:43:39.620101Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = next(iter(train_data_loader))\n",
    "df.keys()"
   ],
   "id": "f7da86e531201f7c",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m df \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mnext\u001B[39m(\u001B[38;5;28miter\u001B[39m(train_data_loader))\n\u001B[0;32m      2\u001B[0m df\u001B[38;5;241m.\u001B[39mkeys()\n",
      "\u001B[1;31mNameError\u001B[0m: name 'train_data_loader' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df['input_ids'].squeeze().shape, df['attention_mask'].squeeze().shape, df['label'].shape",
   "id": "348564b1706a0f0b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print('commit_message  : ', df['commit_message'][0])\n",
    "print('input_ids : ', df['input_ids'].squeeze()[0])\n",
    "print('attention_mask : ', df['attention_mask'].squeeze()[0])\n",
    "print('label : ', df['label'][0])"
   ],
   "id": "aac6b37dd2dfc0a3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "bert_model = BertModel.from_pretrained(BERT_UNCASED)",
   "id": "c266540f915c7596"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "last_hidden_state, pooled_output = bert_model(\n",
    "  input_ids=encodings['input_ids'],\n",
    "  attention_mask=encodings['attention_mask']\n",
    ")"
   ],
   "id": "4c0d141d0223d860"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "last_hidden_state.shape, pooled_output.shape",
   "id": "431aa1070b68805d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class BugPredictor(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_classes):\n",
    "        super(BugPredictor, self).__init__()\n",
    "        self.bert_model = BertModel.from_pretrained(BERT_UNCASED)\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        self.out = nn.Linear(self.bert_model.config.hidden_size, n_classes)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        _, pooled_output = self.bert_model(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask = attention_mask\n",
    "        )\n",
    "        output = self.dropout(pooled_output)\n",
    "        return self.out(output)"
   ],
   "id": "7c1ea14d59ff5462"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\"\n",
    "label 0: Bug\n",
    "label 1: Feature\n",
    "label 2: Question\n",
    "\"\"\"\n",
    "class_names = [0, 1, 2]\n",
    "bug_predictor_model = BugPredictor(len(class_names))\n",
    "bug_predictor_model = bug_predictor_model.to(device)"
   ],
   "id": "513b2fbf7b753de3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "EPOCHS = 5\n",
    "\n",
    "optimizer = AdamW(bug_predictor_model.parameters(), lr=2e-5, correct_bias=False)\n",
    "total_steps = len(train_data_loader) * EPOCHS\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps = 0,\n",
    "    num_training_steps = total_steps\n",
    ")\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)"
   ],
   "id": "5f228a63dab6f3cc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "def train_model(model, data_loader, loss_fn, optimizer, device, scheduler, n_examples):\n",
    "    model = model.train()\n",
    "\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "\n",
    "    for d in data_loader:\n",
    "        input_ids = d['input_ids'].squeeze().to(device)\n",
    "        attention_mask = d['attention_mask'].squeeze().to(device)\n",
    "        targets = d['label'].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "\n",
    "        correct_predictions += torch.sum(preds == targets)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        all_predictions.extend(preds.detach().cpu().numpy())\n",
    "        all_targets.extend(targets.detach().cpu().numpy())\n",
    "\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    accuracy = correct_predictions.double() / n_examples\n",
    "    f1 = f1_score(all_targets, all_predictions, average='weighted')\n",
    "    precision = precision_score(all_targets, all_predictions, average='weighted')\n",
    "    recall = recall_score(all_targets, all_predictions, average='weighted')\n",
    "    mean_loss = np.mean(losses)\n",
    "\n",
    "    return accuracy, f1, precision, recall, mean_loss"
   ],
   "id": "d4c7247a89f0638a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
    "    model = model.eval()\n",
    "\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for d in data_loader:\n",
    "            input_ids = d['input_ids'].squeeze().to(device)\n",
    "            attention_mask = d['attention_mask'].squeeze().to(device)\n",
    "            targets = d['label'].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            \n",
    "            correct_predictions += torch.sum(preds == targets)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            all_predictions.extend(preds.detach().cpu().numpy())\n",
    "            all_targets.extend(targets.detach().cpu().numpy())\n",
    "    \n",
    "    confusion = confusion_matrix(all_targets, all_predictions)\n",
    "    accuracy = correct_predictions.double() / n_examples\n",
    "    f1 = f1_score(all_targets, all_predictions, average='weighted')\n",
    "    precision = precision_score(all_targets, all_predictions, average='weighted')\n",
    "    recall = recall_score(all_targets, all_predictions, average='weighted')\n",
    "    mean_loss = np.mean(losses)\n",
    "\n",
    "    return accuracy, f1, precision, recall, mean_loss, confusion"
   ],
   "id": "c50d3d8c3655d006"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_confusion_matrix(confusion, classes):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(confusion, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    thresh = confusion.max() / 2\n",
    "    for i in range(confusion.shape[0]):\n",
    "        for j in range(confusion.shape[1]):\n",
    "            plt.text(j, i, format(confusion[i, j], 'd'),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if confusion[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "id": "9f4a8c8381c5a83f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%%time\n",
    "from collections import defaultdict\n",
    "\n",
    "history = defaultdict(list)\n",
    "best_accuracy = 0\n",
    "for epoch in range(EPOCHS):\n",
    "    print('EPOCH {}/{}'.format(epoch+1,EPOCHS))\n",
    "    print('-' * 10)\n",
    "    \n",
    "    train_acc, train_f1, train_p, train_recall, train_loss = train_model(bug_predictor_model, train_data_loader, loss_fn, optimizer, device, scheduler, len(training_data))\n",
    "    print(f'Train loss: {train_loss:.4f} F1: {train_f1:.4f}, precision: {train_p:.4f}, recall: {train_recall:.4f}, accuracy: {train_acc:.4f}')\n",
    "    \n",
    "    val_acc, val_f1, val_p, val_recall, val_loss, _ = eval_model(bug_predictor_model, val_data_loader, loss_fn, device, len(validation_data))\n",
    "    print(f'Validation loss: {val_loss:.4f} F1: {val_f1:.4f}, precision: {val_p:.4f}, recall: {val_recall:.4f}, accuracy: {val_acc:.4f}')\n",
    "    \n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    \n",
    "    if val_acc > best_accuracy:\n",
    "        print('Saving the best model ...')\n",
    "        torch.save(bug_predictor_model.state_dict(), 'best_model.bin')\n",
    "        best_accuracy = val_acc"
   ],
   "id": "a9672504ba0c0597"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "_, _, _, _, _, confusion_matrix = eval_model(bug_predictor_model, val_data_loader, loss_fn, device, len(validation_data))\n",
    "class_names = ['bug', 'feature', 'question']\n",
    "plot_confusion_matrix(confusion_matrix, class_names)"
   ],
   "id": "fcb5bb346c102b03"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def predict_git_category(sample_message, model):\n",
    "    encoded_message = tokenizer.encode_plus(sample_bug_message, max_length=MAX_LENGTH, add_special_tokens=True, return_token_type_ids=False, pad_to_max_length=True, return_attention_mask=True, return_tensors='pt')\n",
    "    input_ids = encoded_message['input_ids'].to(device)\n",
    "    attention_mask = encoded_message['attention_mask'].to(device)\n",
    "    \n",
    "    output = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    _, prediction_idx = torch.max(output, dim=1)\n",
    "        \n",
    "    return class_names[prediction_idx]"
   ],
   "id": "f367a9df28d62c7d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "sample_bug_message = \"Script stopped adding video's. A recent change in the youtube layout broke the script. Probably caused by element names being altered.\"\n",
    "print('Sample bug message : ', sample_bug_message)\n",
    "print('Predicted GitHub Category : ', predict_git_category(sample_bug_message, bug_predictor_model))"
   ],
   "id": "1f1081d572337f1e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "sample_message = \"add buttons to switch months when viewing salaah times have  next month  and  previous month  buttons in  masjidvue\"\n",
    "print('Sample bug message : ', sample_message)\n",
    "print('Predicted GitHub Category : ', predict_git_category(sample_message, bug_predictor_model))"
   ],
   "id": "26d703957ee144e6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6f10d9d8e74be1d3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4f4656404df2fcb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
