{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-01T04:06:11.765753Z",
     "start_time": "2024-10-01T04:06:11.759642Z"
    }
   },
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. p.read_csv)\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "        "
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T04:53:34.433680Z",
     "start_time": "2024-10-01T04:53:25.870716Z"
    }
   },
   "cell_type": "code",
   "source": [
    "!pip install tensorflow\n",
    "!pip install tensorflow_hub\n",
    "# !pip3 install tensorflow_text  # can't find version"
   ],
   "id": "4f8b8e297363fdad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (2.17.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.17.0 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from tensorflow) (2.17.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.12.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (4.25.5)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (72.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.66.2)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.17.1)\n",
      "Collecting keras>=3.2.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached keras-3.5.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.17.0->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: rich in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (13.8.1)\n",
      "Requirement already satisfied: namex in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.12.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.1.2)\n",
      "Using cached keras-3.5.0-py3-none-any.whl (1.1 MB)\n",
      "Installing collected packages: keras\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 2.6.0\n",
      "    Uninstalling keras-2.6.0:\n",
      "      Successfully uninstalled keras-2.6.0\n",
      "Successfully installed keras-3.5.0\n",
      "Requirement already satisfied: tensorflow_hub in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (0.16.1)\n",
      "Requirement already satisfied: numpy>=1.12.0 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from tensorflow_hub) (1.26.4)\n",
      "Requirement already satisfied: protobuf>=3.19.6 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from tensorflow_hub) (4.25.5)\n",
      "Requirement already satisfied: tf-keras>=2.14.1 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from tensorflow_hub) (2.17.0)\n",
      "Requirement already satisfied: tensorflow<2.18,>=2.17 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from tf-keras>=2.14.1->tensorflow_hub) (2.17.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.17.0 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (2.17.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (3.12.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (0.4.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (24.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (72.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (1.66.2)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (2.17.1)\n",
      "Requirement already satisfied: keras>=3.2.0 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (3.5.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (0.43.0)\n",
      "Requirement already satisfied: rich in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (13.8.1)\n",
      "Requirement already satisfied: namex in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (0.12.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (3.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (0.1.2)\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T05:06:47.681048Z",
     "start_time": "2024-10-01T05:06:47.630970Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from collections import Counter,defaultdict\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "import plotly.graph_objs as go\n",
    "import plotly.offline as py\n",
    "from plotly import tools\n",
    "py.init_notebook_mode(connected=True)\n",
    "import re\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import LSTM, Dense,Flatten,Conv2D,Conv1D,GlobalMaxPooling1D,GlobalMaxPool1D\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np  \n",
    "import pandas as pd \n",
    "import keras.backend as k\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed, Bidirectional,GRU\n",
    "from tensorflow.keras.models import Model,Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import string\n",
    "import math\n",
    "from scipy.spatial.distance import cosine\n",
    "import transformers\n",
    "from transformers import BertTokenizer,TFBertModel,AutoTokenizer, pipeline\n",
    "from unidecode import unidecode\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%matplotlib inline"
   ],
   "id": "f3987af57d65cd8d",
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.32.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras.preprocessing.text'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[46], line 25\u001B[0m\n\u001B[0;32m     23\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mtf\u001B[39;00m\n\u001B[0;32m     24\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m keras\n\u001B[1;32m---> 25\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpreprocessing\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtext\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Tokenizer\n\u001B[0;32m     26\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlayers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m LSTM, Dense,Flatten,Conv2D,Conv1D,GlobalMaxPooling1D,GlobalMaxPool1D\n\u001B[0;32m     27\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01moptimizers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Adam\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'keras.preprocessing.text'"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### load and analysis data",
   "id": "ae0ef0c49a9fe552"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T04:12:06.732701Z",
     "start_time": "2024-10-01T04:12:05.763896Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_df= pd.read_json(\"resources/embold_train.json\").reset_index(drop=True)\n",
    "train_df.head()"
   ],
   "id": "601a77c315f4c806",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                               title  \\\n",
       "0                                  y-zoom piano roll   \n",
       "1                        buggy behavior in selection   \n",
       "2                                auto update feature   \n",
       "3                 filter out noisy endpoints in logs   \n",
       "4  enable pid on / pid off alarm actions for ardu...   \n",
       "\n",
       "                                                body  label  \n",
       "0        a y-zoom on the piano roll would be useful.      1  \n",
       "1  ! screenshot from 2016-02-23 21 27 40  https:/...      0  \n",
       "2  hi,\\r \\r great job so far, @saenzramiro ! : \\r...      1  \n",
       "3  i think we should stop logging requests to:\\r ...      1  \n",
       "4  expected behavior\\r alarm actions pid on and p...      0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>y-zoom piano roll</td>\n",
       "      <td>a y-zoom on the piano roll would be useful.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>buggy behavior in selection</td>\n",
       "      <td>! screenshot from 2016-02-23 21 27 40  https:/...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>auto update feature</td>\n",
       "      <td>hi,\\r \\r great job so far, @saenzramiro ! : \\r...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>filter out noisy endpoints in logs</td>\n",
       "      <td>i think we should stop logging requests to:\\r ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>enable pid on / pid off alarm actions for ardu...</td>\n",
       "      <td>expected behavior\\r alarm actions pid on and p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T04:12:24.038560Z",
     "start_time": "2024-10-01T04:12:23.854468Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_df= pd.read_json(\"resources/embold_test.json\").reset_index(drop=True)\n",
    "test_df.head()"
   ],
   "id": "fc83b4ba1ae95ce8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                               title  \\\n",
       "0  config question  path-specific environment var...   \n",
       "1                                   crash indien vol   \n",
       "2                               unable to mine rocks   \n",
       "3                   not all whitelists are processed   \n",
       "4          add ctx menu for idafree 70 and idafree 5   \n",
       "\n",
       "                                                body  \n",
       "0  issue description or question\\r \\r hey @artemg...  \n",
       "1                de simulator crasht als hij vol zit  \n",
       "2  sarkasmo starting today, when i hit enter  act...  \n",
       "3  create following rules... order of creation is...  \n",
       "4  associated with .dll, .dll_, .exe, .exe_, .sc,...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>config question  path-specific environment var...</td>\n",
       "      <td>issue description or question\\r \\r hey @artemg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>crash indien vol</td>\n",
       "      <td>de simulator crasht als hij vol zit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>unable to mine rocks</td>\n",
       "      <td>sarkasmo starting today, when i hit enter  act...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>not all whitelists are processed</td>\n",
       "      <td>create following rules... order of creation is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>add ctx menu for idafree 70 and idafree 5</td>\n",
       "      <td>associated with .dll, .dll_, .exe, .exe_, .sc,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T04:12:53.021815Z",
     "start_time": "2024-10-01T04:12:51.241722Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_ex_df= pd.read_json(\"resources/embold_train_extra.json\").reset_index(drop=True)\n",
    "train_ex_df.head()"
   ],
   "id": "f36dee2229d29023",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                               title  \\\n",
       "0                                use a 8bit typeface   \n",
       "1                   implement wireless m-bus binding   \n",
       "2               add multilang support for timeago.js   \n",
       "3                   scaleway - seg-fault on shutdown   \n",
       "4  sistema de pintura: no se guardar los nuevos p...   \n",
       "\n",
       "                                                body  label  \n",
       "0  since this is meant to emulate some old arcade...      1  \n",
       "1  _from  chris.pa...@googlemail.com  https://cod...      1  \n",
       "2  currently it is only  en . \\r required to add ...      1  \n",
       "3  tbr  irc  creates a new scaleway instance with...      0  \n",
       "4  este sp ya estaba asignado a un carro y se enc...      0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>use a 8bit typeface</td>\n",
       "      <td>since this is meant to emulate some old arcade...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>implement wireless m-bus binding</td>\n",
       "      <td>_from  chris.pa...@googlemail.com  https://cod...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>add multilang support for timeago.js</td>\n",
       "      <td>currently it is only  en . \\r required to add ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>scaleway - seg-fault on shutdown</td>\n",
       "      <td>tbr  irc  creates a new scaleway instance with...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sistema de pintura: no se guardar los nuevos p...</td>\n",
       "      <td>este sp ya estaba asignado a un carro y se enc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T04:13:05.843078Z",
     "start_time": "2024-10-01T04:13:05.786144Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mas_train_df = pd.concat([train_df,train_ex_df],ignore_index=True)\n",
    "mas_train_df.head()"
   ],
   "id": "25797a9049c1625c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                               title  \\\n",
       "0                                  y-zoom piano roll   \n",
       "1                        buggy behavior in selection   \n",
       "2                                auto update feature   \n",
       "3                 filter out noisy endpoints in logs   \n",
       "4  enable pid on / pid off alarm actions for ardu...   \n",
       "\n",
       "                                                body  label  \n",
       "0        a y-zoom on the piano roll would be useful.      1  \n",
       "1  ! screenshot from 2016-02-23 21 27 40  https:/...      0  \n",
       "2  hi,\\r \\r great job so far, @saenzramiro ! : \\r...      1  \n",
       "3  i think we should stop logging requests to:\\r ...      1  \n",
       "4  expected behavior\\r alarm actions pid on and p...      0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>y-zoom piano roll</td>\n",
       "      <td>a y-zoom on the piano roll would be useful.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>buggy behavior in selection</td>\n",
       "      <td>! screenshot from 2016-02-23 21 27 40  https:/...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>auto update feature</td>\n",
       "      <td>hi,\\r \\r great job so far, @saenzramiro ! : \\r...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>filter out noisy endpoints in logs</td>\n",
       "      <td>i think we should stop logging requests to:\\r ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>enable pid on / pid off alarm actions for ardu...</td>\n",
       "      <td>expected behavior\\r alarm actions pid on and p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T04:13:15.908094Z",
     "start_time": "2024-10-01T04:13:15.794606Z"
    }
   },
   "cell_type": "code",
   "source": "mas_train_df.info()",
   "id": "3ed7f07ad5dbdcaf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 450000 entries, 0 to 449999\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   title   450000 non-null  object\n",
      " 1   body    450000 non-null  object\n",
      " 2   label   450000 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 10.3+ MB\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T04:16:03.935664Z",
     "start_time": "2024-10-01T04:16:02.883310Z"
    }
   },
   "cell_type": "code",
   "source": "mas_train_df.drop_duplicates(keep='first').count()",
   "id": "8ecdcb85d4d7bf15",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title    450000\n",
       "body     450000\n",
       "label    450000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T04:16:15.889026Z",
     "start_time": "2024-10-01T04:16:12.622471Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def fx(x):\n",
    "    return x['title'] + \" \" + x['body']   \n",
    "mas_train_df['text']= mas_train_df.apply(lambda x : fx(x),axis=1)\n",
    "test_df['text']= test_df.apply(lambda x : fx(x),axis=1)"
   ],
   "id": "2dec46fff397d924",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T04:16:21.447401Z",
     "start_time": "2024-10-01T04:16:21.438379Z"
    }
   },
   "cell_type": "code",
   "source": "mas_train_df.head()",
   "id": "4512c5b3993bb338",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                               title  \\\n",
       "0                                  y-zoom piano roll   \n",
       "1                        buggy behavior in selection   \n",
       "2                                auto update feature   \n",
       "3                 filter out noisy endpoints in logs   \n",
       "4  enable pid on / pid off alarm actions for ardu...   \n",
       "\n",
       "                                                body  label  \\\n",
       "0        a y-zoom on the piano roll would be useful.      1   \n",
       "1  ! screenshot from 2016-02-23 21 27 40  https:/...      0   \n",
       "2  hi,\\r \\r great job so far, @saenzramiro ! : \\r...      1   \n",
       "3  i think we should stop logging requests to:\\r ...      1   \n",
       "4  expected behavior\\r alarm actions pid on and p...      0   \n",
       "\n",
       "                                                text  \n",
       "0  y-zoom piano roll a y-zoom on the piano roll w...  \n",
       "1  buggy behavior in selection ! screenshot from ...  \n",
       "2  auto update feature hi,\\r \\r great job so far,...  \n",
       "3  filter out noisy endpoints in logs i think we ...  \n",
       "4  enable pid on / pid off alarm actions for ardu...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>y-zoom piano roll</td>\n",
       "      <td>a y-zoom on the piano roll would be useful.</td>\n",
       "      <td>1</td>\n",
       "      <td>y-zoom piano roll a y-zoom on the piano roll w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>buggy behavior in selection</td>\n",
       "      <td>! screenshot from 2016-02-23 21 27 40  https:/...</td>\n",
       "      <td>0</td>\n",
       "      <td>buggy behavior in selection ! screenshot from ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>auto update feature</td>\n",
       "      <td>hi,\\r \\r great job so far, @saenzramiro ! : \\r...</td>\n",
       "      <td>1</td>\n",
       "      <td>auto update feature hi,\\r \\r great job so far,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>filter out noisy endpoints in logs</td>\n",
       "      <td>i think we should stop logging requests to:\\r ...</td>\n",
       "      <td>1</td>\n",
       "      <td>filter out noisy endpoints in logs i think we ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>enable pid on / pid off alarm actions for ardu...</td>\n",
       "      <td>expected behavior\\r alarm actions pid on and p...</td>\n",
       "      <td>0</td>\n",
       "      <td>enable pid on / pid off alarm actions for ardu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Clean data",
   "id": "92d7eeb66eb1ce05"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T04:16:35.119946Z",
     "start_time": "2024-10-01T04:16:35.106764Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cList = {\n",
    "            \"i'm\": \"i am\",\n",
    "            \"you're\": \"you are\",\n",
    "            \"it's\": \"it is\",\n",
    "            \"we're\": \"we are\",\n",
    "            \"we'll\": \"we will\",\n",
    "            \"That's\":\"that is\",\n",
    "            \"haven't\":\"have not\",\n",
    "            \"let's\":\"let us\",\n",
    "            \"ain't\": \"am not / are not / is not / has not / have not\",\n",
    "            \"aren't\": \"are not / am not\",\n",
    "            \"can't\": \"cannot\",\n",
    "            \"can't've\": \"cannot have\",\n",
    "            \"'cause\": \"because\",\n",
    "            \"could've\": \"could have\",\n",
    "            \"couldn't\": \"could not\",\n",
    "            \"couldn't've\": \"could not have\",\n",
    "            \"didn't\": \"did not\",\n",
    "            \"doesn't\": \"does not\",\n",
    "            \"don't\": \"do not\",\n",
    "            \"hadn't\": \"had not\",\n",
    "            \"hadn't've\": \"had not have\",\n",
    "            \"hasn't\": \"has not\",\n",
    "            \"haven't\": \"have not\",\n",
    "            \"he'd\": \"he had / he would\",\n",
    "            \"he'd've\": \"he would have\",\n",
    "            \"he'll\": \"he shall / he will\",\n",
    "            \"he'll've\": \"he shall have / he will have\",\n",
    "            \"he's\": \"he has / he is\",\n",
    "            \"how'd\": \"how did\",\n",
    "            \"how'd'y\": \"how do you\",\n",
    "            \"how'll\": \"how will\",\n",
    "            \"how's\": \"how has / how is / how does\",\n",
    "            \"I'd\": \"I had / I would\",\n",
    "            \"I'd've\": \"I would have\",\n",
    "            \"I'll\": \"I shall / I will\",\n",
    "            \"I'll've\": \"I shall have / I will have\",\n",
    "            \"I'm\": \"I am\",\n",
    "            \"I've\": \"I have\",\n",
    "            \"isn't\": \"is not\",\n",
    "            \"it'd\": \"it had / it would\",\n",
    "            \"it'd've\": \"it would have\",\n",
    "            \"it'll\": \"it shall / it will\",\n",
    "            \"it'll've\": \"it shall have / it will have\",\n",
    "            \"it's\": \"it has / it is\",\n",
    "            \"let's\": \"let us\",\n",
    "            \"ma'am\": \"madam\",\n",
    "            \"mayn't\": \"may not\",\n",
    "            \"might've\": \"might have\",\n",
    "            \"mightn't\": \"might not\",\n",
    "            \"mightn't've\": \"might not have\",\n",
    "            \"must've\": \"must have\",\n",
    "            \"mustn't\": \"must not\",\n",
    "            \"mustn't've\": \"must not have\",\n",
    "            \"needn't\": \"need not\",\n",
    "            \"needn't've\": \"need not have\",\n",
    "            \"o'clock\": \"of the clock\",\n",
    "            \"oughtn't\": \"ought not\",\n",
    "            \"oughtn't've\": \"ought not have\",\n",
    "            \"shan't\": \"shall not\",\n",
    "            \"sha'n't\": \"shall not\",\n",
    "            \"shan't've\": \"shall not have\",\n",
    "            \"she'd\": \"she had / she would\",\n",
    "            \"she'd've\": \"she would have\",\n",
    "            \"she'll\": \"she shall / she will\",\n",
    "            \"she'll've\": \"she shall have / she will have\",\n",
    "            \"she's\": \"she has / she is\",\n",
    "            \"should've\": \"should have\",\n",
    "            \"shouldn't\": \"should not\",\n",
    "            \"shouldn't've\": \"should not have\",\n",
    "            \"so've\": \"so have\",\n",
    "            \"so's\": \"so as / so is\",\n",
    "            \"that'd\": \"that would / that had\",\n",
    "            \"that'd've\": \"that would have\",\n",
    "            \"that's\": \"that has / that is\",\n",
    "            \"there'd\": \"there had / there would\",\n",
    "            \"there'd've\": \"there would have\",\n",
    "            \"there's\": \"there has / there is\",\n",
    "            \"they'd\": \"they had / they would\",\n",
    "            \"they'd've\": \"they would have\",\n",
    "            \"they'll\": \"they shall / they will\",\n",
    "            \"they'll've\": \"they shall have / they will have\",\n",
    "            \"they're\": \"they are\",\n",
    "            \"they've\": \"they have\",\n",
    "            \"to've\": \"to have\",\n",
    "            \"wasn't\": \"was not\",\n",
    "            \"we'd\": \"we had / we would\",\n",
    "            \"we'd've\": \"we would have\",\n",
    "            \"we'll\": \"we will\",\n",
    "            \"we'll've\": \"we will have\",\n",
    "            \"we're\": \"we are\",\n",
    "            \"we've\": \"we have\",\n",
    "            \"weren't\": \"were not\",\n",
    "            \"what'll\": \"what shall / what will\",\n",
    "            \"what'll've\": \"what shall have / what will have\",\n",
    "            \"what're\": \"what are\",\n",
    "            \"what's\": \"what has / what is\",\n",
    "            \"what've\": \"what have\",\n",
    "            \"when's\": \"when has / when is\",\n",
    "            \"when've\": \"when have\",\n",
    "            \"where'd\": \"where did\",\n",
    "            \"where's\": \"where has / where is\",\n",
    "            \"where've\": \"where have\",\n",
    "            \"who'll\": \"who shall / who will\",\n",
    "            \"who'll've\": \"who shall have / who will have\",\n",
    "            \"who's\": \"who has / who is\",\n",
    "            \"who've\": \"who have\",\n",
    "            \"why's\": \"why has / why is\",\n",
    "            \"why've\": \"why have\",\n",
    "            \"will've\": \"will have\",\n",
    "            \"won't\": \"will not\",\n",
    "            \"won't've\": \"will not have\",\n",
    "            \"would've\": \"would have\",\n",
    "            \"wouldn't\": \"would not\",\n",
    "            \"wouldn't've\": \"would not have\",\n",
    "            \"y'all\": \"you all\",\n",
    "            \"y'all'd\": \"you all would\",\n",
    "            \"y'all'd've\": \"you all would have\",\n",
    "            \"y'all're\": \"you all are\",\n",
    "            \"y'all've\": \"you all have\",\n",
    "            \"you'd\": \"you had / you would\",\n",
    "            \"you'd've\": \"you would have\",\n",
    "            \"you'll\": \"you shall / you will\",\n",
    "            \"you'll've\": \"you shall have / you will have\",\n",
    "            \"you're\": \"you are\",\n",
    "            \"you've\": \"you have\"\n",
    "           }"
   ],
   "id": "f548ba1a06c07a8b",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T04:17:32.656591Z",
     "start_time": "2024-10-01T04:17:32.649825Z"
    }
   },
   "cell_type": "code",
   "source": "c_re = re.compile('(%s)' % '|'.join(cList.keys()))",
   "id": "4e9e62a48dd3920",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T04:17:37.640799Z",
     "start_time": "2024-10-01T04:17:37.636278Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def expandContractions(text, c_re=c_re):\n",
    "    def replace(match):\n",
    "        return cList[match.group(0)]\n",
    "    return c_re.sub(replace, text)"
   ],
   "id": "62013480a5b17044",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T04:17:46.362586Z",
     "start_time": "2024-10-01T04:17:46.355209Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def remove_emoji(string):\n",
    "        emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "        return emoji_pattern.sub(r'', string) "
   ],
   "id": "35476fc92dc1231e",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T04:17:53.181269Z",
     "start_time": "2024-10-01T04:17:53.176239Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def remove_punctuations(data):\n",
    "    punct_tag=re.compile(r'[^\\w\\s]')\n",
    "    data=punct_tag.sub(r'',data)\n",
    "    return data"
   ],
   "id": "464f0352ea6584a6",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T04:18:06.210933Z",
     "start_time": "2024-10-01T04:18:06.204338Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def removeSpecialChars(data):\n",
    "    '''\n",
    "    Removes special characters which are specifically found in tweets.\n",
    "    '''\n",
    "    #Converts HTML tags to the characters they represent\n",
    "    soup = BeautifulSoup(data, \"html.parser\")\n",
    "    data = soup.get_text()\n",
    "\n",
    "    #Convert www.* or https?://* to empty strings\n",
    "    data = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','',data)\n",
    "\n",
    "    #Convert @username to empty strings\n",
    "    data = re.sub('@[^\\s]+','',data)\n",
    "    \n",
    "    #remove org.apache. like texts\n",
    "    data =  re.sub('(\\w+\\.){2,}','',data)\n",
    "\n",
    "    #Remove additional white spaces\n",
    "    data = re.sub('[\\s]+', ' ', data)\n",
    "    \n",
    "    data = re.sub('\\.(?!$)', '', data)\n",
    "\n",
    "    #Replace #word with word\n",
    "    data = re.sub(r'#([^\\s]+)', r'\\1', data)\n",
    "\n",
    "    return data"
   ],
   "id": "ee8cf05b8115393b",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T04:19:31.221070Z",
     "start_time": "2024-10-01T04:19:31.217075Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def remove_nonenglish_charac(string):\n",
    "    return re.sub('\\W+','', string )"
   ],
   "id": "673403658459d7f4",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T04:22:36.855235Z",
     "start_time": "2024-10-01T04:22:36.851059Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords"
   ],
   "id": "baabdcf4ab20b5dc",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T04:22:38.767507Z",
     "start_time": "2024-10-01T04:22:38.761110Z"
    }
   },
   "cell_type": "code",
   "source": [
    "extra_punctuations = ['','.', '``', '...', '\\'s', '--', '-', 'n\\'t', '_', '','&']\n",
    "stopword_list = stopwords.words('english') + list(string.punctuation)+ extra_punctuations + ['u','the','us','say','that','he','me','she','get','rt','it','mt','via','not','and','let','so','say','dont','use','you']"
   ],
   "id": "4077c822beb04b19",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T04:52:28.182045Z",
     "start_time": "2024-10-01T04:52:28.174794Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def clean_text(data):\n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "    stemmer = PorterStemmer() \n",
    "    tokenizer=TweetTokenizer()\n",
    "    data = unidecode(data)\n",
    "    data = expandContractions(data)\n",
    "    tokens = tokenizer.tokenize(data)\n",
    "    data = ' '.join([tok for tok in tokens if len(tok) > 2 if tok not in stopword_list and not tok.isdigit()])\n",
    "    data = re.sub('\\b\\w{,2}\\b', '', data)\n",
    "    data = re.sub(' +', ' ', data)\n",
    "    data = removeSpecialChars(data)\n",
    "    data = remove_emoji(data)\n",
    "    data= [stemmer.stem(w) for w in data.split()]\n",
    "    return ' '.join([wordnet_lemmatizer.lemmatize(word) for word in data])"
   ],
   "id": "a217f2ca645b0603",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T04:52:38.199058Z",
     "start_time": "2024-10-01T04:52:38.188084Z"
    }
   },
   "cell_type": "code",
   "source": "mas_train_df['text'].head()",
   "id": "a3238ab274fa4c23",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    y-zoom piano roll a y-zoom on the piano roll w...\n",
       "1    buggy behavior in selection ! screenshot from ...\n",
       "2    auto update feature hi,\\r \\r great job so far,...\n",
       "3    filter out noisy endpoints in logs i think we ...\n",
       "4    enable pid on / pid off alarm actions for ardu...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T05:02:59.067390Z",
     "start_time": "2024-10-01T05:02:59.058866Z"
    }
   },
   "cell_type": "code",
   "source": "import unidecode",
   "id": "2f03d880b40b86b2",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T05:03:22.761936Z",
     "start_time": "2024-10-01T05:03:22.628353Z"
    }
   },
   "cell_type": "code",
   "source": "mas_train_df['text']=mas_train_df['text'].apply(lambda x:clean_text(x))",
   "id": "bb31345144fe6df8",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[41], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m mas_train_df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtext\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m=\u001B[39mmas_train_df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtext\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mapply(\u001B[38;5;28;01mlambda\u001B[39;00m x:clean_text(x))\n",
      "File \u001B[1;32m~\\.conda\\envs\\SDPtest\\Lib\\site-packages\\pandas\\core\\series.py:4924\u001B[0m, in \u001B[0;36mSeries.apply\u001B[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001B[0m\n\u001B[0;32m   4789\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply\u001B[39m(\n\u001B[0;32m   4790\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   4791\u001B[0m     func: AggFuncType,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   4796\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m   4797\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DataFrame \u001B[38;5;241m|\u001B[39m Series:\n\u001B[0;32m   4798\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   4799\u001B[0m \u001B[38;5;124;03m    Invoke function on values of Series.\u001B[39;00m\n\u001B[0;32m   4800\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   4915\u001B[0m \u001B[38;5;124;03m    dtype: float64\u001B[39;00m\n\u001B[0;32m   4916\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m   4917\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m SeriesApply(\n\u001B[0;32m   4918\u001B[0m         \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   4919\u001B[0m         func,\n\u001B[0;32m   4920\u001B[0m         convert_dtype\u001B[38;5;241m=\u001B[39mconvert_dtype,\n\u001B[0;32m   4921\u001B[0m         by_row\u001B[38;5;241m=\u001B[39mby_row,\n\u001B[0;32m   4922\u001B[0m         args\u001B[38;5;241m=\u001B[39margs,\n\u001B[0;32m   4923\u001B[0m         kwargs\u001B[38;5;241m=\u001B[39mkwargs,\n\u001B[1;32m-> 4924\u001B[0m     )\u001B[38;5;241m.\u001B[39mapply()\n",
      "File \u001B[1;32m~\\.conda\\envs\\SDPtest\\Lib\\site-packages\\pandas\\core\\apply.py:1427\u001B[0m, in \u001B[0;36mSeriesApply.apply\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1424\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply_compat()\n\u001B[0;32m   1426\u001B[0m \u001B[38;5;66;03m# self.func is Callable\u001B[39;00m\n\u001B[1;32m-> 1427\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply_standard()\n",
      "File \u001B[1;32m~\\.conda\\envs\\SDPtest\\Lib\\site-packages\\pandas\\core\\apply.py:1507\u001B[0m, in \u001B[0;36mSeriesApply.apply_standard\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1501\u001B[0m \u001B[38;5;66;03m# row-wise access\u001B[39;00m\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m \u001B[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001B[39;00m\n\u001B[0;32m   1504\u001B[0m \u001B[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001B[39;00m\n\u001B[0;32m   1505\u001B[0m \u001B[38;5;66;03m#  Categorical (GH51645).\u001B[39;00m\n\u001B[0;32m   1506\u001B[0m action \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(obj\u001B[38;5;241m.\u001B[39mdtype, CategoricalDtype) \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m-> 1507\u001B[0m mapped \u001B[38;5;241m=\u001B[39m obj\u001B[38;5;241m.\u001B[39m_map_values(\n\u001B[0;32m   1508\u001B[0m     mapper\u001B[38;5;241m=\u001B[39mcurried, na_action\u001B[38;5;241m=\u001B[39maction, convert\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconvert_dtype\n\u001B[0;32m   1509\u001B[0m )\n\u001B[0;32m   1511\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(mapped) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(mapped[\u001B[38;5;241m0\u001B[39m], ABCSeries):\n\u001B[0;32m   1512\u001B[0m     \u001B[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001B[39;00m\n\u001B[0;32m   1513\u001B[0m     \u001B[38;5;66;03m#  See also GH#25959 regarding EA support\u001B[39;00m\n\u001B[0;32m   1514\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m obj\u001B[38;5;241m.\u001B[39m_constructor_expanddim(\u001B[38;5;28mlist\u001B[39m(mapped), index\u001B[38;5;241m=\u001B[39mobj\u001B[38;5;241m.\u001B[39mindex)\n",
      "File \u001B[1;32m~\\.conda\\envs\\SDPtest\\Lib\\site-packages\\pandas\\core\\base.py:921\u001B[0m, in \u001B[0;36mIndexOpsMixin._map_values\u001B[1;34m(self, mapper, na_action, convert)\u001B[0m\n\u001B[0;32m    918\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(arr, ExtensionArray):\n\u001B[0;32m    919\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m arr\u001B[38;5;241m.\u001B[39mmap(mapper, na_action\u001B[38;5;241m=\u001B[39mna_action)\n\u001B[1;32m--> 921\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m algorithms\u001B[38;5;241m.\u001B[39mmap_array(arr, mapper, na_action\u001B[38;5;241m=\u001B[39mna_action, convert\u001B[38;5;241m=\u001B[39mconvert)\n",
      "File \u001B[1;32m~\\.conda\\envs\\SDPtest\\Lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001B[0m, in \u001B[0;36mmap_array\u001B[1;34m(arr, mapper, na_action, convert)\u001B[0m\n\u001B[0;32m   1741\u001B[0m values \u001B[38;5;241m=\u001B[39m arr\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;28mobject\u001B[39m, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m na_action \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1743\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m lib\u001B[38;5;241m.\u001B[39mmap_infer(values, mapper, convert\u001B[38;5;241m=\u001B[39mconvert)\n\u001B[0;32m   1744\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1745\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m lib\u001B[38;5;241m.\u001B[39mmap_infer_mask(\n\u001B[0;32m   1746\u001B[0m         values, mapper, mask\u001B[38;5;241m=\u001B[39misna(values)\u001B[38;5;241m.\u001B[39mview(np\u001B[38;5;241m.\u001B[39muint8), convert\u001B[38;5;241m=\u001B[39mconvert\n\u001B[0;32m   1747\u001B[0m     )\n",
      "File \u001B[1;32mlib.pyx:2972\u001B[0m, in \u001B[0;36mpandas._libs.lib.map_infer\u001B[1;34m()\u001B[0m\n",
      "Cell \u001B[1;32mIn[41], line 1\u001B[0m, in \u001B[0;36m<lambda>\u001B[1;34m(x)\u001B[0m\n\u001B[1;32m----> 1\u001B[0m mas_train_df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtext\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m=\u001B[39mmas_train_df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtext\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mapply(\u001B[38;5;28;01mlambda\u001B[39;00m x:clean_text(x))\n",
      "Cell \u001B[1;32mIn[33], line 5\u001B[0m, in \u001B[0;36mclean_text\u001B[1;34m(data)\u001B[0m\n\u001B[0;32m      3\u001B[0m stemmer \u001B[38;5;241m=\u001B[39m PorterStemmer() \n\u001B[0;32m      4\u001B[0m tokenizer\u001B[38;5;241m=\u001B[39mTweetTokenizer()\n\u001B[1;32m----> 5\u001B[0m data \u001B[38;5;241m=\u001B[39m unidecode(data)\n\u001B[0;32m      6\u001B[0m data \u001B[38;5;241m=\u001B[39m expandContractions(data)\n\u001B[0;32m      7\u001B[0m tokens \u001B[38;5;241m=\u001B[39m tokenizer\u001B[38;5;241m.\u001B[39mtokenize(data)\n",
      "\u001B[1;31mTypeError\u001B[0m: 'module' object is not callable"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T04:52:53.947717Z",
     "start_time": "2024-10-01T04:52:53.941119Z"
    }
   },
   "cell_type": "code",
   "source": "mas_train_df['text'].head()",
   "id": "997371d10ec536a8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    y-zoom piano roll a y-zoom on the piano roll w...\n",
       "1    buggy behavior in selection ! screenshot from ...\n",
       "2    auto update feature hi,\\r \\r great job so far,...\n",
       "3    filter out noisy endpoints in logs i think we ...\n",
       "4    enable pid on / pid off alarm actions for ardu...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T05:04:11.706600Z",
     "start_time": "2024-10-01T05:04:11.691164Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Convert the textual reviews to list for analysing sentences(sentence vectors)\n",
    "text_lst = mas_train_df['text'].tolist()"
   ],
   "id": "610afe91e3c61fa",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "fbbd45fa6d14f8c0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T05:06:21.123956Z",
     "start_time": "2024-10-01T05:06:18.421831Z"
    }
   },
   "cell_type": "code",
   "source": "!pip3 install tensorflow-hub",
   "id": "ab35ce239f62e229",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-hub in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (0.16.1)\n",
      "Requirement already satisfied: numpy>=1.12.0 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from tensorflow-hub) (1.26.4)\n",
      "Requirement already satisfied: protobuf>=3.19.6 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from tensorflow-hub) (4.25.5)\n",
      "Requirement already satisfied: tf-keras>=2.14.1 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from tensorflow-hub) (2.17.0)\n",
      "Requirement already satisfied: tensorflow<2.18,>=2.17 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from tf-keras>=2.14.1->tensorflow-hub) (2.17.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.17.0 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow-hub) (2.17.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow-hub) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow-hub) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow-hub) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow-hub) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow-hub) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow-hub) (3.12.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow-hub) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow-hub) (0.4.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow-hub) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow-hub) (24.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow-hub) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow-hub) (72.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow-hub) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow-hub) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow-hub) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow-hub) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow-hub) (1.66.2)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow-hub) (2.17.1)\n",
      "Requirement already satisfied: keras>=3.2.0 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow-hub) (3.5.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow-hub) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow-hub) (0.43.0)\n",
      "Requirement already satisfied: rich in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow-hub) (13.8.1)\n",
      "Requirement already satisfied: namex in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow-hub) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow-hub) (0.12.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow-hub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow-hub) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow-hub) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow-hub) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow-hub) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow-hub) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow-hub) (3.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow-hub) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow-hub) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow-hub) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\yc\\.conda\\envs\\sdptest\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow-hub) (0.1.2)\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T05:06:25.285367Z",
     "start_time": "2024-10-01T05:06:25.250123Z"
    }
   },
   "cell_type": "code",
   "source": [
    "elmo = hub.load(\"https://tfhub.dev/google/elmo/2\")\n",
    "# model load failed"
   ],
   "id": "5033fb07e126547d",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hub' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[45], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m elmo \u001B[38;5;241m=\u001B[39m hub\u001B[38;5;241m.\u001B[39mload(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttps://tfhub.dev/google/elmo/2\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'hub' is not defined"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def create_elmo_embeddings(data):\n",
    "    embed=elmo(data,signature=\"default\",as_dict=True)[\"elmo\"]\n",
    "    print(embed.shape)\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        sess.run(tf.tables_initializer())\n",
    "        out_x=sess.run(embed)\n",
    "        # return average of ELMo features\n",
    "        return out_x"
   ],
   "id": "675a0fbf9d9e51ac"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#elmo_input = text_lst[:2]\n",
    "#elmo_output = create_elmo_embeddings(elmo_input)"
   ],
   "id": "dc746ab3aec71683"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "bert_tokenizer =  BertTokenizer.from_pretrained('bert-large-uncased', do_lower_case=True)\n",
    "bert_model = TFBertModel.from_pretrained('bert-large-uncased')"
   ],
   "id": "3802aadb9aa119f9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def bert_encode(data,max_len):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    for i in range(len(data)):\n",
    "        encoded = bert_tokenizer.encode_plus(\n",
    "        \n",
    "          data[i],\n",
    "          add_special_tokens = True,\n",
    "          max_length = max_len,\n",
    "          pad_to_max_length = True,        \n",
    "          return_attention_mask = True,        \n",
    "        )\n",
    "        input_ids.append(encoded['input_ids'])\n",
    "        attention_masks.append(encoded['attention_mask'])\n",
    "    return np.array(input_ids),np.array(attention_masks)\n",
    "        "
   ],
   "id": "4ec5b5d1958deb73"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "train_input_ids,train_attention_masks = bert_encode(mas_train_df['text'][:5],1000)",
   "id": "f4a70d139ea79fcc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "input_ids = tf.keras.layers.Input(shape=(128,), name='input_token', dtype='int32')\n",
    "input_masks_ids = tf.keras.layers.Input(shape=(128,), name='masked_token', dtype='int32')\n",
    "bert_output=bert_model([input_ids,input_masks_ids])[0]\n",
    "bert_output.shape\n",
    "bert_output[:,0,:]\n",
    "model=Model(inputs=[input_ids,input_masks_ids],outputs=[bert_output])\n",
    "model.summary()"
   ],
   "id": "2b0b6a6b3c1b0cc3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def Get_Transformer_Embedding(transformer_model,tokenizer,name,inp):\n",
    "    tokenizr = tokenizer.from_pretrained(name)\n",
    "    model = transformer_model.from_pretrained(name)\n",
    "    input_ids = tf.constant(tokenizr.encode(inp))[None,:]\n",
    "    outputs = model(input_ids)\n",
    "    lst_hidd_state = outputs[0]\n",
    "    return lst_hidd_state[0]  "
   ],
   "id": "89db5a8cb9f50106"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "cls_token = Get_Transformer_Embedding(TFBertModel,BertTokenizer,'bert-base-uncased',text_lst[0])\n",
    "print(cls_token)\n",
    "print(cls_token.shape)\n",
    "plt.plot(cls_token[0])\n",
    "plt.plot(cls_token[1])\n",
    "plt.show()"
   ],
   "id": "eb2a7e99cf30073c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def build_transformer_embedding(name,inp,model_name,IsGpt = False):\n",
    "\n",
    "    model = model_name.from_pretrained(name)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(name)\n",
    "    if IsGpt:\n",
    "        tokenizer.pad_token = \"[PAD]\"        \n",
    "    pipe = pipeline('feature-extraction', model=model,tokenizer=tokenizer)\n",
    "    features = pipe(inp)\n",
    "    features = np.squeeze(features)\n",
    "    return features"
   ],
   "id": "635b9df2292091ca"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def Generate_Embedding(name,model_name,IsGpt = False):\n",
    "    embedding_features1 = build_transformer_embedding(name,text_lst[0],model_name,IsGpt)\n",
    "    embedding_features2 = build_transformer_embedding(name,text_lst[1],model_name,IsGpt)\n",
    "    distance= 1- cosine(embedding_features1[0],embedding_features2[0])\n",
    "    print(distance)\n",
    "    plt.plot(embedding_features1[0])\n",
    "    plt.plot(embedding_features2[0])"
   ],
   "id": "3081f9d9aaadbd3e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from transformers import TFDistilBertModel\n",
    "Generate_Embedding('distilbert-base-uncased',TFDistilBertModel)"
   ],
   "id": "85a2a98f9ac8390e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
